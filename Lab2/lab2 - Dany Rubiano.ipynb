{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab2 - Dany Rubiano.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"e2JwmJM9EjmH","colab_type":"text"},"cell_type":"markdown","source":["# Laboratorio 2 Redes Neuronales"]},{"metadata":{"id":"rEJJstwFEjmL","colab_type":"text"},"cell_type":"markdown","source":["##### Profesor: Gonzalo Acuña\n","##### Ayudante: Ignacio Ibañez\n","##### Alumno: Dany Rubiano "]},{"metadata":{"id":"S5g0vNFEEjmN","colab_type":"text"},"cell_type":"markdown","source":["## 1. Funciones de Transferencia\n","Las funciones de transferencia tienen como objetivo decidir si una neurona debe activarse o no. Son un proceso algorítmico que transforman el resultado de la función de propagación en la salida real de la neurona.\n","En la función de transferencia el valor de la salida de combinación puede ser comparada con algún valor umbral para determinar la salida de la neurona. Si la suma es mayor que el valor umbral, neurona generará una señal. Si la suma es menor que el valor umbral, ninguna señal será generada.\n","\n","Existen dos tipos de funciones de transferencia segun su linealidad, leneales o no lineales.  \n","\n","### 1.1 Función de Transferencia Lineal\n","Las funciones de transferencia lineales tienen un comportamiento similar a la de una línea recta. Si en una red neuronal todas las capas son de naturaleza lineal, la función de transferencia final de la última capa no es más que una función lineal de la entrada de la primera capa.\n","\n","Entre las funciones de transferencia lineales se encuentra la función ReLU, rectificador o unidad lineal rectificada (Rectified Linear Unit), que corresponde a una función lineal real de un solo argumento, continua y diferenciable en todo su dominio, exceptuando el inicio de la rama. \n","Se define formalmente como f(x) = max(0,x), donde x pertenece a la entrada de la neurona. La función toma un valor de 0 para entradas negativas y toma valores equivalentes a la entrada cuando son entradas 0 o positivas.\n","\n","### 1.2 Función de Transferencia No Lineal\n","Las funciones de transferencia no lineales son aquellas que tienen más de un grado, por lo que su comportamiento es como el de una curva. Al utilizar una función de transferencia no lineal en una red neuronal, se pueden generar asignaciones no lineales desde las entradas a las salidas.\n","\n","Una de las funciones de transferencia no lineales es la función sigmoidea, la cual tiene la forma matemática:\n","\n","![sigmo.png](attachment:sigmo.png)\n","Esta función toma un número de valor real y lo transforma a un valor en el rango entre 0 y 1. En particular, los números negativos grandes se convierten en 0 y los números positivos grandes se convierten en 1. \n","\n","\n","\n","## 2. Código de las funciones de transferencia"]},{"metadata":{"id":"8pMMvmjbEjmR","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Codigo de la primera actividad\n","\n","# funcion de transferencia lineal \n","class ReLU(object):\n","\n","    def __init__(self):\n","        return\n","\n","    def relu(self, x):\n","        if x < 0:\n","            return 0\n","        if x >= 0:\n","            return x\n","\n","    def drelu(self, x):\n","        if x < 0:\n","            return 0\n","        if x >= 0:\n","            return 1\n","    \n","    def function(self, x):\n","        x = np.vectorize(self.relu)(x)\n","        return x\n","    \n","    def derivate(self, x):\n","        x = np.vectorize(self.drelu)(x)\n","        return x\n","\n","# Funcion de transferencia no lineal\n","class Sigmoid(object):\n","    def __init__(self):\n","        return\n","    \n","    def function(self, x):\n","        return 1/(1+np.exp(-x))\n","    \n","    def derivate(self, x):\n","        return np.exp(-x)/((1+np.exp(-x))**2)  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZN0e5mTmEjmb","colab_type":"text"},"cell_type":"markdown","source":["## 3. Funciones Objetivo (Loss Functions)\n","Las funciones objetivo se utilizan para medir la inconsistencia entre el valor predicho (^y) y el valor real (y).\n","Es un valor no negativo, donde la solidez del modelo aumenta a medida que disminuye el valor de la función objetivo. \n","\n","En esta ocasión se trabajará con el error cuadrático medio y la entropía cruzada.\n","\n","### 3.1. Error medio cuadrado\n","La función de error cuadrático medio (MSE) tiene como objetivo minimizar la suma cuadrática del residual enntre el valor preddicho y el valor real.\n","![MSE.png](attachment:MSE.png)\n","\n","### 3.2. Entropía  Cruzada\n","La entropía cruzada mide la divergencia entre dos distribución de probabilidad, si la entropía cruzada es grande, significa que la diferencia entre dos distribuciones es grande, mientras que si la entropía cruzada es pequeña, significa que dos distribuciones son similares entre sí. \n","![CE.png](attachment:CE.png)\n","\n","\n","## 4. Código de las funciones objetivo"]},{"metadata":{"id":"Qjwsrqx8Ejmd","colab_type":"code","colab":{}},"cell_type":"code","source":["# loss functions\n","\n","def MSE(self, X, y):\n","    self.yHat = self.forward(X)\n","    J = (1/(self.inputLayerSize))*sum((y-self.yHat)**2)\n","    return J\n","\n","def CE(self, X, y):\n","    self.yHat = self.forward(X)\n","    J = -(1/(self.inputLayerSize))*sum(y*np.log(self.yHat)+(1-y)*np.log(1-self.yHat))\n","    return J"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7DB2CT6qEjml","colab_type":"text"},"cell_type":"markdown","source":["## 5. Red feed-forward\n","Las redes neuronales feed-forward son redes donde las conexiones entre las unidades no forman un ciclo. Fueron el primer tipo de red neuronal artificial inventada y son más simples que sus contrapartes como las redes neuronales recurrentes. Su nombre es referido porque la información solo se desplaza hacia adelante en la red, primero a través de los nodos de entrada, luego a través de los nodos ocultos y finalmente a través de los nodos de salida.\n","\n","![feed-forward.PNG](attachment:feed-forward.PNG)\n","\n","## 6. Código de la red feed-forward"]},{"metadata":{"id":"tQ01H1PbEjmn","colab_type":"code","colab":{}},"cell_type":"code","source":["class Neural_Network(object):\n","    def __init__(self, inputLayerSize, outputLayerSize, hiddenLayerSize, activationFunction, lossFunction):        \n","        #Define Hyperparameters\n","        self.inputLayerSize = inputLayerSize\n","        self.outputLayerSize = outputLayerSize\n","        self.hiddenLayerSize = hiddenLayerSize\n","        self.activationFunction = activationFunction\n","        self.lossFunction = lossFunction\n","        \n","        #Weights (parameters)\n","        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n","        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n","        \n","    def forward(self, X):\n","        #Propogate inputs though network\n","        self.z2 = np.dot(X, self.W1)\n","        self.a2 = self.activationFunction.function(self.z2)\n","        self.z3 = np.dot(self.a2, self.W2)\n","        yHat = self.activationFunction.function(self.z3) \n","        return yHat\n","    \n","    def costFunction(self, X, y):\n","        #Compute cost for given X,y, use weights already stored in class.\n","        #self.yHat = self.forward(X)\n","        if self.lossFunction == 'MSE':\n","            J = MSE(self, X, y)\n","        elif self.lossFunction == 'CE':\n","            J = CE(self, X, y)\n","        return J\n","    \n","    def dabs(self, y, yHat):\n","        if y > yHat:\n","            return 0\n","        if y < yHat:\n","            return 1\n","        \n","    def costFunctionPrime(self, X, y):\n","        #Compute derivative with respect to W and W2 for a given X and y:\n","        self.yHat = self.forward(X)\n","        \n","        delta3 = np.multiply(-(y-self.yHat), self.activationFunction.derivate(self.z3))\n","        dJdW2 = np.dot(self.a2.T, delta3)\n","        \n","        delta2 = np.dot(delta3, self.W2.T)*self.activationFunction.derivate(self.z2)\n","        dJdW1 = np.dot(X.T, delta2)  \n","        \n","        return dJdW1, dJdW2\n","    \n","    #Helper Functions for interacting with other classes:\n","    def getParams(self):\n","        #Get W1 and W2 unrolled into vector:\n","        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n","        return params\n","    \n","    def setParams(self, params):\n","        #Set W1 and W2 using single paramater vector.\n","        W1_start = 0\n","        W1_end = self.hiddenLayerSize * self.inputLayerSize\n","        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n","        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n","        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n","        \n","    def computeGradients(self, X, y):\n","        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n","        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n","\n","\n","def computeNumericalGradient(N, X, y):\n","        paramsInitial = N.getParams()\n","        numgrad = np.zeros(paramsInitial.shape)\n","        perturb = np.zeros(paramsInitial.shape)\n","        e = 1e-4\n","\n","        for p in range(len(paramsInitial)):\n","            #Set perturbation vector\n","            perturb[p] = e\n","            N.setParams(paramsInitial + perturb)\n","            loss2 = N.costFunction(X, y)\n","            \n","            N.setParams(paramsInitial - perturb)\n","            loss1 = N.costFunction(X, y)\n","\n","            #Compute Numerical Gradient\n","            numgrad[p] = (loss2 - loss1) / (2*e)\n","\n","            #Return the value we changed to zero:\n","            perturb[p] = 0\n","            \n","        #Return Params to original value:\n","        N.setParams(paramsInitial)\n","\n","        return numgrad \n","    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v4aFacl6Ejms","colab_type":"text"},"cell_type":"markdown","source":["## 7. Código de entrenamiento de la red"]},{"metadata":{"id":"VIAfASIOEjmv","colab_type":"code","colab":{}},"cell_type":"code","source":["from scipy import optimize\n","\n","class trainer(object):\n","    def __init__(self, N):\n","        #Make Local reference to network:\n","        self.N = N\n","        \n","    def callbackF(self, params):\n","        self.N.setParams(params)\n","        self.J.append(self.N.costFunction(self.X, self.y))\n","        self.testJ.append(self.N.costFunction(self.testX, self.testY))\n","        \n","    def costFunctionWrapper(self, params, X, y):\n","        self.N.setParams(params)\n","        cost = self.N.costFunction(X, y)\n","        grad = self.N.computeGradients(X,y)\n","        \n","        return cost, grad\n","        \n","    def train(self, trainX, trainY, testX, testY):\n","        #Make an internal variable for the callback function:\n","        self.X = trainX\n","        self.y = trainY\n","        \n","        self.testX = testX\n","        self.testY = testY\n","\n","        #Make empty list to store training costs:\n","        self.J = []\n","        self.testJ = []\n","        \n","        params0 = self.N.getParams()\n","\n","        options = {'maxiter': 200, 'disp' : True}\n","        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n","                                 args=(trainX, trainY), options=options, callback=self.callbackF)\n","\n","        self.N.setParams(_res.x)\n","        self.optimizationResults = _res"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sFTayy5uEjm1","colab_type":"code","colab":{},"outputId":"f7526703-e5b7-41f0-a9fd-f6a9db2e4919"},"cell_type":"code","source":["# AND\n","#X = np.array(([0,0], [0,1], [1,0], [1,1]), dtype=float)\n","#y = np.array(([0], [0], [0], [1]), dtype=float)\n","\n","#Xtest = np.array(([0,0], [0,1], [1,1]), dtype=float)\n","#ytest = np.array(([0], [0], [1]), dtype=float)\n","\n","# OR\n","#X = np.array(([0,0], [0,1], [1,0], [1,1]), dtype=float)\n","#y = np.array(([0], [1], [1], [1]), dtype=float)\n","\n","#Xtest = np.array(([0,0], [0,1], [1,0]), dtype=float)\n","#ytest = np.array(([0], [1], [1]), dtype=float)\n","\n","# XOR\n","X = np.array(([0,0], [0,1], [1,0], [1,1]), dtype=float)\n","y = np.array(([0], [1], [1], [0]), dtype=float)\n","\n","Xtest = np.array(([0,0], [0,1], [1,0]), dtype=float)\n","ytest = np.array(([0], [1], [1]), dtype=float)\n","\n","X = X\n","y = y  \n","\n","S = Sigmoid()\n","R = ReLU()\n","#NN = Neural_Network(2, 1, 2, S, 'MSE') \n","#NN = Neural_Network(2, 1, 2, S, 'CE')\n","NN = Neural_Network(2, 1, 2, R, 'MSE')\n","#NN = Neural_Network(2, 1, 2, R, 'CE')\n","\n","T = trainer(NN)\n","T.train(X, y, Xtest, ytest)\n","\n","plt.plot(T.J)\n","plt.plot(T.testJ)\n","plt.grid(1)\n","plt.title('Iteraciones vs Costo')\n","plt.xlabel('Iteraciones')\n","plt.ylabel('Costo')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Optimization terminated successfully.\n","         Current function value: 0.000000\n","         Iterations: 7\n","         Function evaluations: 8\n","         Gradient evaluations: 8\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Text(0,0.5,'Costo')"]},"metadata":{"tags":[]},"execution_count":124},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<matplotlib.figure.Figure at 0x25528451400>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"2C9LCJqwEjnG","colab_type":"text"},"cell_type":"markdown","source":["## 8. Análisis de resultados\n","\n","Al experimentar con cada una de las compuertas lógicas, los resultados reflejan que los modelos se ajustan en pocas iteraciones en la compuerta OR, mientras que la compuerta AND requiere un poco más de iteraciones, mientras que por otro lado, la compuerta XOR en muchos casos no logra ajustarse de manera correcta.\n","\n","En una comparación de los resultados en la combinatoria entre la red feed-forward y los parámetros de las funciones de transferecia y las funciones objetivo, se pudo obtener que en las mayoria de los casos la función ReLU en combinación con la función MSE otorga mejores resultados que las otras combinaciones, en términos de la cantidad de iteraciones necesarias y su costo final. Sin embargo, cabe destacar que al probar con una función de transferencia ReLU y la función objetivo de entropía cruzada (CE), el modelo resultaba con un error que no pudo ser controlado. Si se siguiera la lógica de los resultados que mostró la función sigmoide en combinación con la función CE, en comparación con sigmoide y MSE, se podría inferir que ReLU y CE hubiera podido tener los mejores resultados, aunque hay que tomar en cuenta que la combinatoria entre modelos puede arrojar diferentes resultados en función de sus propiedades matemáticas conjuntas. \n","\n","Lo anterior se puede comprobar en la teoría, en la cual se encuentra que al utilizar sigmoid como la función de transferencia, la función MSE sufre el problema de la convergencia lenta, mientras que para otras funciones de activación, no tendría ese problema, tal como se pudo evidenciar en la combinatoria con ReLU. \n","Al comparar MSE con CE, se desstaca que CE tiene las ventajas de una convergencia rápida y es más probable que alcance la optimización global. \n","\n","En cuanto a las funciones de transferencia, la función sigmoide a diferencia de las funciones lineales, tiene una salida en el rango (0,1) en comparación con (0, inf) de ReLU, por lo que las activaciones estan ligadas a un rango, lo que supondría un mayor control sobre las activaciones. Por otro lado, ReLU es menos costoso que sigmoide  porque implica operaciones matemáticas más simples y además presenta la ventaja de ser más livina que sigmoide en el proceso de activación, dadas sus características matemáticas.\n","\n","\n","\n","## 9. Descripción del dataset escogido\n","El dataset Iris es un conjunto de datos multivariante introducido por Ronald Fisher en su papel de 1936 The use of multiple measurements in taxonomic problems, como un ejemplo de análisis discriminante lineal. Representa datos usados para cuantificar la variación morfológica del Iris con flores de tres especies relacionadas. El conjunto de datos contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). Mide cuatro rasgos de cada muestra: lo largo y lo ancho del sépalos y pétalos, en centímetros. Basado en la combinación de estos cuatro rasgos, Fisher se desarrolló un modelo discriminante lineal para distinguir entre una especie y otra. Este es quizás el dataset más conocido que se encuentra en la literatura de reconocimiento de patrones.\n","\n","Teniendo en cuenta las características del dataset, como no tiene ningún atricbuto perdido y las clases tienen la misma cantidad de instancias, no es necesario un preprocesamiento que vaya más allá de la normalización de los datos.\n","\n","## 10. Código del trabajo con el dataset"]},{"metadata":{"id":"C_4ry_kNFVPd","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"e1b9Q1voEjnH","colab_type":"code","colab":{},"outputId":"e79ef46a-b0d9-44b2-db45-086b0a5ed752"},"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import normalize\n","\n","# Lectura del dataset\n","data = load_iris()\n","X = data.data\n","X = normalize(X)\n","clasificacion = data.target\n","total = clasificacion.shape[0]\n","T = []\n","for i in range(total):\n","    T.append([1,clasificacion[i]])\n","    \n","    \n","#Prueba y entrenamiento\n","X_train, X_test, Y_train, Y_test = train_test_split(X, T, test_size=0.3)\n","print('Train: {train}, Test: {test}'.format(train=X_train.shape[0], test=X_test.shape[0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train: 105, Test: 45\n"],"name":"stdout"}]},{"metadata":{"id":"H9OTTACtEjnN","colab_type":"text"},"cell_type":"markdown","source":["## 11. Resultados"]},{"metadata":{"id":"HXuBSgHsEjnP","colab_type":"code","colab":{},"outputId":"c092a7df-1251-4618-e1bd-21a95008e298"},"cell_type":"code","source":["S = Sigmoid()\n","R = ReLU()\n","NN = Neural_Network(4, 2, 3, S, 'MSE') \n","#NN = Neural_Network(4, 2, 3, S, 'CE')\n","#NN = Neural_Network(4, 2, 3, R, 'MSE')\n","#NN = Neural_Network(4, 2, 3, R, 'CE')\n","\n","T = trainer(NN)\n","T.train(X_train, Y_train, X_test, Y_test)\n","#T2 = trainer(NN2)\n","#T2.train(X,y)\n","\n","plt.plot(T.J)\n","plt.plot(T.testJ)\n","plt.grid(1)\n","plt.title('Iteraciones vs Error')\n","plt.xlabel('Iteraciones')\n","plt.ylabel('Error')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-122-c940bfd2b168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#T2 = trainer(NN2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#T2.train(X,y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-105-b158bb536618>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, trainX, trainY, testX, testY)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'disp'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0m_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcostFunctionWrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BFGS'\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbackF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[1;32m--> 964\u001b[1;33m                                           old_fval, old_old_fval, amin=1e-100, amax=1e100)\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[1;31m# Line search failed to find a better solution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m    781\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0;32m    782\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m                              **kwargs)\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[0;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mold_phi0\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mderphi0\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.01\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mold_phi0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mderphi0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malpha1\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"]}]},{"metadata":{"id":"SPVJXKuiEjnV","colab_type":"text"},"cell_type":"markdown","source":["## 12. Análisis de resultados\n","Lamentablemente, no se pudieron conseguir los resultados debido a un error.\n","\n","## 13. Conclusiones\n","\n","Una vez concluida la experiencia, se pudo llevar a cabo la implementación de una red neuronal feed-forward, obteniendo inferencias acerca de las funciones de transferencia lineales vs no lineales y de las funciones objetivo, en las que se pudo ver las diferencias entre dos ejemplos como sigmoide y ReLU, y MSE y entropía cruzada, y los resultados de su combinatoria. \n","\n","En temas de la experiencia en general, no se pudieron llevar a cabo todos los objetivos propuestos, ya que se tuvieron problemas en probar el dataset escogido, por lo que no se pudieron presentar los resultados y su análisis correspondiente.\n","\n","Se espera seguir en experiencias futuras seguir implementando otros tipos de redes neuronales, ahondando en el aprendizaje profundo.\n","\n","## 14. Referencias\n","\n","Isaac Changhau (2017). Loss Functions in Neural Networks. Recuperado desde https://isaacchanghau.github.io/post/loss_functions/\n","\n","Sagar Sharma (2017). Activation Functions: Neural Networks. Recuperado desde https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n","\n","Tushar Gupta (2017). Deep Learning: Feedforward Neural Network. Recuperado desde https://towardsdatascience.com/deep-learning-feedforward-neural-network-26a6705dbdc7\n","\n","John McGonagle (2018). Feedforward Neural Networks. Recuperado desde https://brilliant.org/wiki/feedforward-neural-networks/"]},{"metadata":{"id":"vlSU5rdxEjnW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}
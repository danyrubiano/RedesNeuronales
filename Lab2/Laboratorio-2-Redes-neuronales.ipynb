{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Laboratorio-2-Redes-neuronales.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9rFmMlybuWCH","colab_type":"text"},"source":["#### Profesor: Gonzalo Acuña L. Ayudante: Ignacio Ibañez\n","#### Alumno: Diego Polanco B. Rut: 18.662.203-0\n"]},{"cell_type":"markdown","metadata":{"id":"_FYeR76AuWCI","colab_type":"text"},"source":["# Parte 1: Funciones de activación\n"]},{"cell_type":"markdown","metadata":{"id":"O8YJXK85uWCJ","colab_type":"text"},"source":["El principal propósito de la Función de Activación de un nodo radica en definir la salida de éste, dada una entrada en específico o ya sea un conjunto de entradas. Tiene un funcionamiento similar al del perceptron, detallado en la experiencia anterior. En el presente laboratorio se solicitó realizar en primera instancia una función de transferencia lineal y una de carácter no lineal. Por lo que se escogió implementar la función ReLU (unidad lineal rectificada) como una función de transferencia lineal y la función de tangente hiperbolica como una función de transferencia no lineal.\n"]},{"cell_type":"markdown","metadata":{"id":"cGdKXesvuWCK","colab_type":"text"},"source":["### Función de transferencia lineal (ReLU)"]},{"cell_type":"markdown","metadata":{"id":"t-Y3FqLguWCL","colab_type":"text"},"source":["ReLU, rectificador o unidad lineal rectificada (Rectified Linear Unit) corresponde a una función real de un solo argumento, continua y diferenciable en todo su dominio, exceptuando el inicio de la rama.\n","Esta funcion de activación se define como f(x) = max(0,x), donde x pertenece a la entrada de la neurona. Esto quiere decir que la función toma un valor de 0 para entradas negativas y toma valores equivalentes a la entrada cuando son entradas 0 o positivas.\n","![ReLU](relu.png)"]},{"cell_type":"code","metadata":{"id":"3B2RwY41uWCL","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","X = np.array(([0,0], [0,1], [1,0], [1,1]), dtype=float)\n","y = np.array(([1], [1], [1], [0]), dtype=float)\n","\n","Xtest = np.array(([0,0], [0,1], [1,0]), dtype=float)\n","ytest = np.array(([1], [1], [1]), dtype=float)\n","\n","X = X\n","y = y  \n","\n","class ReLU(object):\n","\n","    def __init__(self):\n","        return\n","\n","    def relu(self, x):\n","        if x < 0:\n","            return 0\n","        if x >= 0:\n","            return x\n","\n","    def drelu(self, x):\n","        if x < 0:\n","            return 0\n","        if x >= 0:\n","            return 1\n","    \n","    def function(self, x):\n","        x = np.vectorize(self.relu)(x)\n","        return x\n","    \n","    def derivate(self, x):\n","        x = np.vectorize(self.drelu)(x)\n","        return x\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0qEggqH1uWCP","colab_type":"text"},"source":["### Funcion de transferencia no lineal (Tanh)"]},{"cell_type":"markdown","metadata":{"id":"1z4ticf5uWCP","colab_type":"text"},"source":["Otra de las funciones de activación seleccionadas para su implementación, fue la tangente hiperbólica. La tangente hiperbólica o Tanh corresponde a una función real, continua y diferenciable, el cual se expressa como el cociente entre el seno hiperbólico y el coseno hiperbólico. ![Tangente hiperbolica](tanh.png) \n","A su vez esta función se expresa en funciones exponenciales de bases irracionales e y exponente x.![Tangente hiperbolica](tanh1.png) ![Tangente hiperbolica](tangenteh.png)"]},{"cell_type":"code","metadata":{"id":"lPjnltmWuWCQ","colab_type":"code","colab":{}},"source":["class Tanh(object):\n","    def __init__(self):\n","        return\n","    \n","    def function(self, x):\n","        return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n","    \n","    def derivate(self, x):\n","        return 4/((np.exp(x)+np.exp(-x))**2)        \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5c6W9hT7uWCS","colab_type":"text"},"source":["# Parte 2: Funciones objetivo"]},{"cell_type":"markdown","metadata":{"id":"OFl8rUl9uWCT","colab_type":"text"},"source":["Las funciones objetivo representa que tan lejos se encuentran las predicciones realizadas de la solución optima al problema a resolver. Permite expresar exactamente que tan costoso es nuestro modelo realizado. Para la realización de este laboratorio se implementaron dos funciones de costo u objetivo, las cuales son la función de error absoluto medio y la función de error cuadrático medio.\n","El error absoluto medio permite calcular el promedio entre la distancia del valor predicho esperado y la salida obtenida. Esta función se representa matematicamente de la siguiente forma:![MAE](mae.png)\n","El error cuadratico medio corresponde a una estimación promedio de errores al cuadrado entre los valores predichos esperados y la salida obtenida. La ECM está dada por:![ECM](ecm.png)"]},{"cell_type":"code","metadata":{"id":"QjG7ZVlYuWCT","colab_type":"code","colab":{}},"source":["def ECM(self, X, y):\n","    self.yHat = self.forward(X)\n","    J = (1/(self.inputLayerSize))*sum((y-self.yHat)**2)\n","    return J\n","    \n","def MAE(self, X, y):\n","    self.yHat = self.forward(X)\n","    J = (1/(self.inputLayerSize))*sum(abs(y-self.yHat))\n","    return J\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nNmTUQf8uWCV","colab_type":"text"},"source":["# Parte 3: Red neuronal feed forward"]},{"cell_type":"markdown","metadata":{"id":"MoJqfASZuWCW","colab_type":"text"},"source":["Una red neuronal feed forward corresponde a la primera y más sencilla red neuronal ideada, ya que su funcionamiento se basa solamente en mover la información hacia adelante, sin realizar ninguna especie de ciclo. Dentro de este tipo de redes neuronales se pueden encontrar el perceptrón de una capa, el cual consta de una sola capa de nodos de entrada y una de nodos de salida, los cuales se encuentran directamente conectados mediante una serie de ponderaciones. Otra de las redes que corresponden al tipo feed forward son los perceptrones multicapa, en este caso consta de capas de entrada, de salida y capas ocultas. Esto permite resolver problemas que no son linealmente separables, el cual es la principal limitación del perceptron simple. En este caso la red multicapa puede ser totalmente o localmente conectada, la cual se diferencia por la cantidad de neuronas que son entradas para la siguiente capa.![Feed forward](feed.gif)\n","A continuación se presentan dos redes neuronales, las cuales se componen por las distintas funciones objetivo mencionadas anteriormente.\n"]},{"cell_type":"code","metadata":{"id":"nsze4BUXuWCW","colab_type":"code","colab":{}},"source":["class Neural_NetworkMSE(object):\n","    def __init__(self, inputLayerSize, outputLayerSize, hiddenLayerSize, activationFunction):        \n","        #Define Hyperparameters\n","        self.inputLayerSize = inputLayerSize\n","        self.outputLayerSize = outputLayerSize\n","        self.hiddenLayerSize = hiddenLayerSize\n","        self.activationFunction = activationFunction\n","        \n","        #Weights (parameters)\n","        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n","        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n","        \n","    def forward(self, X):\n","        #Propogate inputs though network\n","        self.z2 = np.dot(X, self.W1)\n","        self.a2 = self.activationFunction.function(self.z2)\n","        self.z3 = np.dot(self.a2, self.W2)\n","        yHat = self.activationFunction.function(self.z3) \n","        return yHat\n","    \n","    def costFunction(self, X, y):\n","        #Compute cost for given X,y, use weights already stored in class.\n","        self.yHat = self.forward(X)\n","        J = (1/(self.inputLayerSize))*sum((y-self.yHat)**2)\n","        return J\n","        \n","    def costFunctionPrime(self, X, y):\n","        #Compute derivative with respect to W and W2 for a given X and y:\n","        self.yHat = self.forward(X)\n","        \n","        delta3 = np.multiply(-(y-self.yHat), self.activationFunction.derivate(self.z3))\n","        dJdW2 = np.dot(self.a2.T, delta3)\n","        \n","        delta2 = np.dot(delta3, self.W2.T)*self.activationFunction.derivate(self.z2)\n","        dJdW1 = np.dot(X.T, delta2)  \n","        \n","        return dJdW1, dJdW2\n","    \n","    #Helper Functions for interacting with other classes:\n","    def getParams(self):\n","        #Get W1 and W2 unrolled into vector:\n","        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n","        return params\n","    \n","    def setParams(self, params):\n","        #Set W1 and W2 using single paramater vector.\n","        W1_start = 0\n","        W1_end = self.hiddenLayerSize * self.inputLayerSize\n","        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n","        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n","        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n","        \n","    def computeGradients(self, X, y):\n","        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n","        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n","\n","class Neural_NetworkAE(object):\n","    def __init__(self, inputLayerSize, outputLayerSize, hiddenLayerSize, activationFunction):        \n","        #Define Hyperparameters\n","        self.inputLayerSize = inputLayerSize\n","        self.outputLayerSize = outputLayerSize\n","        self.hiddenLayerSize = hiddenLayerSize\n","        self.activationFunction = activationFunction\n","        \n","        #Weights (parameters)\n","        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n","        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n","        \n","    def forward(self, X):\n","        #Propogate inputs though network\n","        self.z2 = np.dot(X, self.W1)\n","        self.a2 = self.activationFunction.function(self.z2)\n","        self.z3 = np.dot(self.a2, self.W2)\n","        yHat = self.activationFunction.function(self.z3) \n","        return yHat\n","    \n","    def costFunction(self, X, y):\n","        #Compute cost for given X,y, use weights already stored in class.\n","        self.yHat = self.forward(X)\n","        J = (1/(self.inputLayerSize))*sum(abs(y-self.yHat))\n","        return J\n","\n","    def dabs(self, y, yHat):\n","        if y > yHat:\n","            return 0\n","        if y < yHat:\n","            return 1\n","        \n","    def costFunctionPrime(self, X, y):\n","        #Compute derivative with respect to W and W2 for a given X and y:\n","        self.yHat = self.forward(X)\n","        v = np.vectorize(self.dabs)(y,self.yHat)\n","        \n","        delta3 = np.multiply(-(v), self.activationFunction.derivate(self.z3))\n","        dJdW2 = np.dot(self.a2.T, delta3)\n","        \n","        delta2 = np.dot(delta3, self.W2.T)*self.activationFunction.derivate(self.z2)\n","        dJdW1 = np.dot(X.T, delta2)  \n","        \n","        return dJdW1, dJdW2\n","    \n","    #Helper Functions for interacting with other classes:\n","    def getParams(self):\n","        #Get W1 and W2 unrolled into vector:\n","        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n","        return params\n","    \n","    def setParams(self, params):\n","        #Set W1 and W2 using single paramater vector.\n","        W1_start = 0\n","        W1_end = self.hiddenLayerSize * self.inputLayerSize\n","        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n","        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n","        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n","        \n","    def computeGradients(self, X, y):\n","        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n","        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n","\n","def computeNumericalGradient(N, X, y):\n","        paramsInitial = N.getParams()\n","        numgrad = np.zeros(paramsInitial.shape)\n","        perturb = np.zeros(paramsInitial.shape)\n","        e = 1e-4\n","\n","        for p in range(len(paramsInitial)):\n","            #Set perturbation vector\n","            perturb[p] = e\n","            N.setParams(paramsInitial + perturb)\n","            loss2 = N.costFunction(X, y)\n","            \n","            N.setParams(paramsInitial - perturb)\n","            loss1 = N.costFunction(X, y)\n","\n","            #Compute Numerical Gradient\n","            numgrad[p] = (loss2 - loss1) / (2*e)\n","\n","            #Return the value we changed to zero:\n","            perturb[p] = 0\n","            \n","        #Return Params to original value:\n","        N.setParams(paramsInitial)\n","\n","        return numgrad     "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SwnQ2yfTuWCY","colab_type":"text"},"source":["# Parte 4: Entrenamiento Red neuronal feedforward"]},{"cell_type":"markdown","metadata":{"id":"E9s-gw67uWCZ","colab_type":"text"},"source":["A continuación se realiza el entrenamiento de la red neuronal elaborada, mediante a las funciones de activación mencionadas con anterioridad."]},{"cell_type":"code","metadata":{"id":"_PWryCt4uWCa","colab_type":"code","colab":{},"outputId":"5f111b4c-b3fb-4a35-ad4c-e54e9aea1afb"},"source":["from scipy import optimize\n","\n","\n","class trainer(object):\n","    def __init__(self, N):\n","        #Make Local reference to network:\n","        self.N = N\n","        \n","    def callbackF(self, params):\n","        self.N.setParams(params)\n","        self.J.append(self.N.costFunction(self.X, self.y))\n","        self.testJ.append(self.N.costFunction(self.testX, self.testY))\n","        \n","    def costFunctionWrapper(self, params, X, y):\n","        self.N.setParams(params)\n","        cost = self.N.costFunction(X, y)\n","        grad = self.N.computeGradients(X,y)\n","        \n","        return cost, grad\n","        \n","    def train(self, trainX, trainY, testX, testY):\n","        #Make an internal variable for the callback function:\n","        self.X = trainX\n","        self.y = trainY\n","        \n","        self.testX = testX\n","        self.testY = testY\n","\n","        #Make empty list to store training costs:\n","        self.J = []\n","        self.testJ = []\n","        \n","        params0 = self.N.getParams()\n","\n","        options = {'maxiter': 200, 'disp' : True}\n","        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n","                                 args=(trainX, trainY), options=options, callback=self.callbackF)\n","\n","        self.N.setParams(_res.x)\n","        self.optimizationResults = _res\n","\n","\n","\n","T = Tanh()\n","#R = ReLU()\n","NN = Neural_NetworkMSE(2, 1, 3, T) \n","#NN2 = Neural_NetworkAE(2, 1, 3, T) \n","T = trainer(NN)\n","T.train(X,y, Xtest, ytest)\n","#T2 = trainer(NN2)\n","#T2.train(X,y, Xtest, ytest)\n","\n","\n","plt.plot(T.J)\n","plt.plot(T.testJ)\n","plt.grid(1)\n","plt.xlabel('Iterations')\n","plt.ylabel('Cost')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Optimization terminated successfully.\n","         Current function value: 0.500000\n","         Iterations: 107\n","         Function evaluations: 142\n","         Gradient evaluations: 142\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Text(0,0.5,'Cost')"]},"metadata":{"tags":[]},"execution_count":41},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"bIcw336BuWCf","colab_type":"text"},"source":["# Análisis de resultados"]},{"cell_type":"markdown","metadata":{"id":"Mz6u6VaMuWCg","colab_type":"text"},"source":["En el ejercicio anterior se busca evaluar las distintas redes neuoronales realizadas con las funciones objetivos basadas en el error absoluto medio y la función de error cuadrático medio. Además se utilizaron las funciones de activación ReLU y la tangente hiperbolica, realizando todas las combinaciones. Como se puede apreciar en el grafico anterior, el modelo necesita de pocas iteraciones para aproximarse a la función de costo deseada. Luego de esto la red sigue iterando sin variar el valor del costo."]},{"cell_type":"markdown","metadata":{"id":"bFVu7aTxuWCh","colab_type":"text"},"source":["# Parte 5: Dataset Load Breast Cancer"]},{"cell_type":"markdown","metadata":{"id":"95F44oEluWCh","colab_type":"text"},"source":["Se escogió el dataset \"load_breast_cancer\", el cual entrega 569 casos de personas con tumores mamarios y posee 2 clases, benigno y maligno. Dentro de estos 569 casos, 212 son del tipo maligno y 357 del tipo benigno. Este dataset contiene una dimensionalidad de 30 caracteristicas por cada caso analizado."]},{"cell_type":"code","metadata":{"id":"0Mht3kJsuWCi","colab_type":"code","colab":{},"outputId":"99c80652-b566-4e82-aca0-37e5f9750c7d"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import normalize\n","from sklearn.metrics import confusion_matrix\n","\n","cancer = load_breast_cancer()\n","x_entrenamiento = cancer.data\n","y = cancer.target\n","y_entrenamiento = np.zeros([len(y), 3])\n","\n","for i in range(len(y)):    \n","\ty_entrenamiento[i][y[i]] = 1\n","\n","#X = np.array(([0,0], [0,1], [1,0], [1,1]), dtype=float)\n","#y = np.array(([0], [1], [1], [1]), dtype=float)\n","\n","x_entrenamiento = normalize(x_entrenamiento)\n","x_entrenamiento, x_test, y_entrenamiento, y_test = train_test_split(x_entrenamiento, y_entrenamiento, test_size=0.3)\n","print('Tamaño entrenamiento: {train}, Tamaño test: {test}'.format(train=x_entrenamiento.shape[0], test=x_test.shape[0]))\n","\n","#print(x_entrenamiento)\n","#print(y_entrenamiento)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tamaño entrenamiento: 398, Tamaño test: 171\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dg_7m1xsuWCl","colab_type":"text"},"source":["# Analisis comparativo"]},{"cell_type":"markdown","metadata":{"id":"dPPVH0isuWCl","colab_type":"text"},"source":["Como se explicó en el laboratorio anterior las Extreme Learning Machine o ELM son redes neuronales predictivas utilizadas para clasificación, regresión, clustering y aprendizaje de características con una más capas de nodos ocultos, entre otros. Comparado con las redes neuronales convencionales, alcanza una mayor velocidad de entrenamiento y resuelve de mejor manera los problemas de ajuste excesivo. Las ELM se basan en la minimización de riesgos y su proceso de aprendizaje solo necesita una iteración. El algoritmo evita múltiples iteraciones y minimización local. Siendo esta última característica la principal diferenciadora de las redes feed forward, ya que utiliza multiples iteraciones. Por lo que no se puede afirmar que una opción sea mejor que otra, ya que si bien puede que la red feed forward obtenga una mayor presición la mayoría de las veces, ocupa un mayor tiempo de computo, por lo que sería ideal para problemas que no manejen tantas variables. En cambio la ELM podría ser de mayor utilidad en problemas de mayor complejidad o con mayor cantidad de variables o neuronas, ya que solo necesita de una sola iteración."]},{"cell_type":"markdown","metadata":{"id":"TlBPXjXMuWCm","colab_type":"text"},"source":["# Conclusiones"]},{"cell_type":"markdown","metadata":{"id":"xRc7iIeIuWCn","colab_type":"text"},"source":["En el presente laboratorio se puso en practica la elaboración de la red neuronal feed forward en base a distintas funciones de activación y funciones objetivo realizando una combinación de éstas. En primera instancia se implementaron una funcion de transferencia lineal (ReLU) y una funcion de transferencia no lineal (Tangente hiperbolica). A continuación se realizaron las funciones de coste u objetivo basadas en el error absoluto medio y en la función de error cuadrático medio. Siguiendo con la experiencia se elaboraron las redes neuronales propuestas con una unica capa oculta, en donde se debían probar con las compuertas logicas AND, OR y XOR.\n","Luego se solicitaba seleccionar el data set utilizado en el laboratorio 1, para luego normalizar los datos. En el laboratorio anterior se seleccionó un dataset, el cual evaluaba los tumores mamarios mediante a 30 caracteristicas. Es importante recalcar que existieron objetivos que no se pudieron realizar debido a que no se pudo superar los problemas que conllevaba la implementación de ellos.\n","En esta experiencia se aprendió que la red neuronal feed forward puede ser de gran utilidad para problemas que no manejen tantas variables, debido a que su tiempo de computo sería muy elevado. En el caso de manejar una gran cantidad de variables sería mejor ocupar una ELM.\n","En las siguientes experiencias se tiene el objetivo de seguir aplicando la teoria aprendida en clases, para aprender los pro y contra de utilizar las distintas redes neuronales. "]}]}